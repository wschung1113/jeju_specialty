{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting absl-py==2.1.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate==0.21.0\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: adagio==0.2.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.2.4)\n",
      "Requirement already satisfied: aiohttp==3.9.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (3.9.3)\n",
      "Collecting aiohttp-cors==0.7.0\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: aiosignal==1.3.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.3.1)\n",
      "Collecting alembic==1.13.1\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aliyun-python-sdk-core==2.15.0\n",
      "  Downloading aliyun-python-sdk-core-2.15.0.tar.gz (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.1/443.1 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aliyun-python-sdk-kms==2.16.2\n",
      "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.3\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anyio==4.3.0\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: appdirs==1.4.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.4.4)\n",
      "Collecting arrow==1.3.0\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: asttokens==2.4.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (2.4.1)\n",
      "Requirement already satisfied: async-timeout==4.0.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (4.0.3)\n",
      "Requirement already satisfied: attrs==23.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (23.2.0)\n",
      "Collecting autogluon==1.0.0\n",
      "  Downloading autogluon-1.0.0-py3-none-any.whl (9.9 kB)\n",
      "Collecting autogluon.common==1.0.0\n",
      "  Downloading autogluon.common-1.0.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.core==1.0.0\n",
      "  Downloading autogluon.core-1.0.0-py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.features==1.0.0\n",
      "  Downloading autogluon.features-1.0.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.multimodal==1.0.0\n",
      "  Downloading autogluon.multimodal-1.0.0-py3-none-any.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.7/416.7 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.tabular==1.0.0\n",
      "  Downloading autogluon.tabular-1.0.0-py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.timeseries==1.0.0\n",
      "  Downloading autogluon.timeseries-1.0.0-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backoff==2.2.1\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting beautifulsoup4==4.12.3\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting blessed==1.20.0\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blis==0.7.11\n",
      "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting boto3==1.34.68\n",
      "  Downloading boto3-1.34.68-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore==1.34.68\n",
      "  Downloading botocore-1.34.68-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools==5.3.3\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Collecting catalogue==2.0.10\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: catboost==1.2.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (1.2.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 33)) (2024.2.2)\n",
      "Collecting cffi==1.16.0\n",
      "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer==3.3.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (3.3.2)\n",
      "Collecting click==8.1.7\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cloudpathlib==0.16.0\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle==3.0.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (3.0.0)\n",
      "Collecting cmake==3.28.4\n",
      "  Downloading cmake-3.28.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting colorama==0.4.6\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting colorful==0.5.6\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting colorlog==6.8.2\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 43)) (0.2.2)\n",
      "Collecting confection==0.1.4\n",
      "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: contourpy==1.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 45)) (1.2.0)\n",
      "Collecting crcmod==1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting croniter==1.4.1\n",
      "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting cryptography==42.0.5\n",
      "  Downloading cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.12.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 49)) (0.12.1)\n",
      "Collecting cymem==2.0.8\n",
      "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Cython==3.0.9 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 51)) (3.0.9)\n",
      "Requirement already satisfied: darts==0.28.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 52)) (0.28.0)\n",
      "Collecting datasets==2.18.0\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dateutils==0.6.12\n",
      "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: debugpy==1.8.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 55)) (1.8.1)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 56)) (5.1.1)\n",
      "Collecting deepdiff==6.7.1\n",
      "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting defusedxml==0.7.1\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting dill==0.3.8\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distlib==0.3.8\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting editor==1.6.6\n",
      "  Downloading editor-1.6.6-py3-none-any.whl (4.0 kB)\n",
      "Collecting evaluate==0.4.1\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: exceptiongroup==1.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (1.2.0)\n",
      "Requirement already satisfied: executing==2.0.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 64)) (2.0.1)\n",
      "Collecting fastai==2.7.14\n",
      "  Downloading fastai-2.7.14-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.2/232.2 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastapi==0.110.0\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastcore==1.5.29\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fastdownload==0.0.7\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastprogress==1.0.3\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: filelock==3.13.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 70)) (3.13.1)\n",
      "Requirement already satisfied: fonttools==4.50.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 71)) (4.50.0)\n",
      "Requirement already satisfied: frozenlist==1.4.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 72)) (1.4.1)\n",
      "Requirement already satisfied: fs==2.4.16 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 73)) (2.4.16)\n",
      "Collecting fsspec==2024.2.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fugue==0.8.7 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 75)) (0.8.7)\n",
      "Requirement already satisfied: fugue-sql-antlr==0.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 76)) (0.2.0)\n",
      "Collecting future==1.0.0\n",
      "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gdown==5.1.0\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Collecting gluonts==0.14.4\n",
      "  Downloading gluonts-0.14.4-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core==2.18.0\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth==2.29.0\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting googleapis-common-protos==1.63.0\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gpustat==1.1.1\n",
      "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: graphviz==0.20.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 84)) (0.20.2)\n",
      "Collecting greenlet==3.0.3\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio==1.62.1\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting h11==0.14.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: holidays==0.45 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 88)) (0.45)\n",
      "Collecting huggingface-hub==0.21.4\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hyperopt==0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna==3.6 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 91)) (3.6)\n",
      "Collecting imageio==2.34.0\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting inquirer==3.2.4\n",
      "  Downloading inquirer-3.2.4-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: ipykernel==6.29.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 94)) (6.29.3)\n",
      "Requirement already satisfied: ipython==8.22.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 95)) (8.22.2)\n",
      "Collecting itsdangerous==2.1.2\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: jedi==0.19.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 97)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 98)) (3.1.3)\n",
      "Collecting jmespath==0.10.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: joblib==1.3.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 100)) (1.3.2)\n",
      "Collecting jsonschema==4.17.3\n",
      "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jupyter_client==8.6.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 102)) (8.6.1)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 103)) (5.7.2)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 104)) (1.4.5)\n",
      "Collecting langcodes==3.3.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lazy_loader==0.3\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting lightgbm==4.1.0\n",
      "  Downloading lightgbm-4.1.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning==2.0.9.post0\n",
      "  Downloading lightning-2.0.9.post0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-cloud==0.5.65\n",
      "  Downloading lightning_cloud-0.5.65-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightning-utilities==0.11.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 110)) (0.11.0)\n",
      "Collecting lit==18.1.2\n",
      "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: llvmlite==0.42.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 112)) (0.42.0)\n",
      "Requirement already satisfied: lunardate==0.2.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 113)) (0.2.2)\n",
      "Collecting Mako==1.3.2\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Markdown==3.6\n",
      "  Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown-it-py==3.0.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe==2.1.5 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 117)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib==3.8.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 118)) (3.8.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 119)) (0.1.6)\n",
      "Collecting mdurl==0.1.2\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting mlforecast==0.10.0\n",
      "  Downloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting model-index==0.1.11\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: mpmath==1.3.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 123)) (1.3.0)\n",
      "Collecting msgpack==1.0.8\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multidict==6.0.5 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 125)) (6.0.5)\n",
      "Collecting multiprocess==0.70.16\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting murmurhash==1.0.10\n",
      "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 128)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.2.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 129)) (3.2.1)\n",
      "Requirement already satisfied: nfoursid==1.0.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 130)) (1.0.1)\n",
      "Collecting nlpaug==1.1.11\n",
      "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nltk==3.8.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nptyping==2.4.1\n",
      "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: numba==0.59.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 134)) (0.59.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 135)) (1.26.4)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 137)) (12.1.3.1)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 139)) (12.1.105)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 141)) (12.1.105)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 143)) (12.1.105)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 145)) (8.9.2.26)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 147)) (11.0.2.54)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 149)) (10.3.2.106)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 151)) (11.4.5.107)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 153)) (12.1.0.106)\n",
      "Collecting nvidia-ml-py==12.535.133\n",
      "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 157)) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 158)) (12.4.99)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 160)) (12.1.105)\n",
      "Collecting omegaconf==2.2.3\n",
      "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencensus==0.11.4\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencensus-context==0.1.3\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting opendatalab==0.0.10\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Collecting openmim==0.3.9\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openxlab==0.0.36\n",
      "  Downloading openxlab-0.0.36-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.5/302.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optuna==3.6.0\n",
      "  Downloading optuna-3.6.0-py3-none-any.whl (379 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.9/379.9 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ordered-set==4.1.0\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Collecting orjson==3.9.15\n",
      "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oss2==2.17.0\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging==24.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 171)) (24.0)\n",
      "Collecting pandas==2.1.4\n",
      "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 173)) (0.8.3)\n",
      "Requirement already satisfied: patsy==0.5.6 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 174)) (0.5.6)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 175)) (4.9.0)\n",
      "Requirement already satisfied: pillow==10.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 176)) (10.2.0)\n",
      "Collecting platformdirs==3.11.0\n",
      "  Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: plotly==5.20.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 178)) (5.20.0)\n",
      "Requirement already satisfied: pmdarima==2.0.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 179)) (2.0.4)\n",
      "Collecting preshed==3.0.9\n",
      "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting prometheus_client==0.20.0\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit==3.0.43 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 182)) (3.0.43)\n",
      "Collecting proto-plus==1.23.0\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf==4.25.3\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil==5.9.8 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 185)) (5.9.8)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 186)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 187)) (0.2.2)\n",
      "Collecting py-spy==0.3.14\n",
      "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting py4j==0.10.9.7\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow==15.0.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 190)) (15.0.2)\n",
      "Collecting pyarrow-hotfix==0.6\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting pyasn1==0.5.1\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyasn1-modules==0.3.0\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycparser==2.21\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Collecting pycryptodome==3.20.0\n",
      "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic==1.10.14\n",
      "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pygments==2.17.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 197)) (2.17.2)\n",
      "Collecting PyJWT==2.8.0\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyod==1.1.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 199)) (1.1.3)\n",
      "Requirement already satisfied: pyparsing==3.1.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 200)) (3.1.2)\n",
      "Collecting pyrsistent==0.20.0\n",
      "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PySocks==1.7.1\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting pytesseract==0.3.10\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 204)) (2.9.0.post0)\n",
      "Collecting python-multipart==0.0.9\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pytimekr==0.1.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 206)) (0.1.0)\n",
      "Collecting pytorch-lightning==2.0.9.post0\n",
      "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl (727 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-metric-learning==1.7.3\n",
      "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz==2023.4\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting PyWavelets==1.5.0\n",
      "  Downloading pywavelets-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML==6.0.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 211)) (6.0.1)\n",
      "Requirement already satisfied: pyzmq==25.1.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 212)) (25.1.2)\n",
      "Requirement already satisfied: qpd==0.4.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 213)) (0.4.4)\n",
      "Collecting ray==2.6.3\n",
      "  Downloading ray-2.6.3-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting readchar==4.0.6\n",
      "  Downloading readchar-4.0.6-py3-none-any.whl (8.5 kB)\n",
      "Collecting regex==2023.12.25\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests==2.28.2\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting responses==0.18.0\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting rich==13.4.2\n",
      "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa==4.9\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting runs==1.2.2\n",
      "  Downloading runs-1.2.2-py3-none-any.whl (7.0 kB)\n",
      "Collecting s3transfer==0.10.1\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors==0.4.2\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image==0.20.0\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==1.4.1.post1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 225)) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy==1.12.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 226)) (1.12.0)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 227)) (0.13.2)\n",
      "Collecting sentencepiece==0.2.0\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting seqeval==1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: shap==0.45.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 230)) (0.45.0)\n",
      "Requirement already satisfied: six==1.16.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 231)) (1.16.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 232)) (0.0.7)\n",
      "Collecting smart-open==6.4.0\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio==1.3.1\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting soupsieve==2.5\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Collecting spacy==3.7.4\n",
      "  Downloading spacy-3.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy==3.0.12\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers==1.0.5\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting SQLAlchemy==2.0.28\n",
      "  Downloading SQLAlchemy-2.0.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sqlglot==23.0.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 240)) (23.0.3)\n",
      "Collecting srsly==2.4.8\n",
      "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: stack-data==0.6.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 242)) (0.6.3)\n",
      "Collecting starlette==0.36.3\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starsessions==1.3.0\n",
      "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting statsforecast==1.4.0\n",
      "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: statsmodels==0.14.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 246)) (0.14.1)\n",
      "Requirement already satisfied: sympy==1.12 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 247)) (1.12)\n",
      "Collecting tabulate==0.9.0\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: tbats==1.1.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 249)) (1.1.3)\n",
      "Requirement already satisfied: tenacity==8.2.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 250)) (8.2.3)\n",
      "Collecting tensorboard==2.16.2\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server==0.7.2\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboardX==2.6.2.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 253)) (2.6.2.2)\n",
      "Collecting text-unidecode==1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thinc==8.2.3\n",
      "  Downloading thinc-8.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (922 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.3/922.3 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl==3.3.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 256)) (3.3.0)\n",
      "Collecting tifffile==2024.2.12\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting timm==0.9.16\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers==0.13.3\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting toolz==0.12.1\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics==1.1.2\n",
      "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.15.2\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado==6.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 264)) (6.4)\n",
      "Collecting tqdm==4.65.2\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: traitlets==5.14.2 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 266)) (5.14.2)\n",
      "Collecting transformers==4.31.0\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: triad==0.9.6 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 268)) (0.9.6)\n",
      "Collecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer==0.9.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting types-python-dateutil==2.9.0.20240316\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: typing_extensions==4.10.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 272)) (4.10.0)\n",
      "Requirement already satisfied: tzdata==2024.1 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 273)) (2024.1)\n",
      "Collecting urllib3==1.26.18\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting utilsforecast==0.0.10\n",
      "  Downloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
      "Collecting uvicorn==0.29.0\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting virtualenv==20.21.0\n",
      "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi==1.1.2\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 279)) (0.2.13)\n",
      "Collecting weasel==0.3.4\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websocket-client==1.7.0\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets==12.0\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Werkzeug==3.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting window_ops==0.0.15\n",
      "  Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: xarray==2024.2.0 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 285)) (2024.2.0)\n",
      "Requirement already satisfied: xgboost==2.0.3 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 286)) (2.0.3)\n",
      "Collecting xmod==1.8.1\n",
      "  Downloading xmod-1.8.1-py3-none-any.whl (4.6 kB)\n",
      "Collecting xxhash==3.4.1\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: yarl==1.9.4 in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from -r requirements.txt (line 289)) (1.9.4)\n",
      "Requirement already satisfied: setuptools in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from autogluon.common==1.0.0->-r requirements.txt (line 18)) (65.5.0)\n",
      "Requirement already satisfied: pip in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from fastai==2.7.14->-r requirements.txt (line 65)) (23.0.1)\n",
      "Requirement already satisfied: requests[socks] in /home/wschung1113/.pyenv/versions/3.10.13/envs/timeseries_env/lib/python3.10/site-packages (from gdown==5.1.0->-r requirements.txt (line 78)) (2.31.0)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyzmq to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyzmq==25.1.2\n",
      "  Using cached pyzmq-25.1.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)\n",
      "INFO: pip is looking at multiple versions of pyyaml to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyYAML==6.0.1\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "INFO: pip is looking at multiple versions of pywavelets to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pytz to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pytorch-metric-learning to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pytorch-lightning to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pytimekr to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pytimekr==0.1.0\n",
      "  Using cached pytimekr-0.1.0.tar.gz (7.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of python-multipart to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of python-dateutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting python-dateutil==2.9.0.post0\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "INFO: pip is looking at multiple versions of pytesseract to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pysocks to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyrsistent to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyparsing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyparsing==3.1.2\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "INFO: pip is looking at multiple versions of pyod to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyod==1.1.3\n",
      "  Using cached pyod-1.1.3.tar.gz (160 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of pyjwt to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Pygments==2.17.2\n",
      "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pycryptodome to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pycparser to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyasn1-modules to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyasn1 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyarrow-hotfix to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyarrow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyarrow==15.0.2\n",
      "  Using cached pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "INFO: pip is looking at multiple versions of py4j to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of py-spy to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pure-eval to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pure-eval==0.2.2\n",
      "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of ptyprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ptyprocess==0.7.0\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of psutil to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting psutil==5.9.8\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "INFO: pip is looking at multiple versions of protobuf to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of proto-plus to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of prompt-toolkit to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting prompt-toolkit==3.0.43\n",
      "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
      "INFO: pip is looking at multiple versions of prometheus-client to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of preshed to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pmdarima to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pmdarima==2.0.4\n",
      "  Using cached pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "INFO: pip is looking at multiple versions of plotly to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting plotly==5.20.0\n",
      "  Using cached plotly-5.20.0-py3-none-any.whl (15.7 MB)\n",
      "INFO: pip is looking at multiple versions of platformdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pillow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pillow==10.2.0\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "INFO: pip is looking at multiple versions of pexpect to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pexpect==4.9.0\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "INFO: pip is looking at multiple versions of patsy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting patsy==0.5.6\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "INFO: pip is looking at multiple versions of parso to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting parso==0.8.3\n",
      "  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "INFO: pip is looking at multiple versions of pandas to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of packaging to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting packaging==24.0\n",
      "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "INFO: pip is looking at multiple versions of oss2 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of orjson to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of ordered-set to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of optuna to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of openmim to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opendatalab to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opencensus-context to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of opencensus to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of omegaconf to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-nvtx-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "INFO: pip is looking at multiple versions of nvidia-nvtx-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-nvjitlink-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.99\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-nccl-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-nccl-cu12==2.19.3\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-nccl-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-ml-py3 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-ml-py to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cusparse-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cusparse-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cusolver-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cusolver-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-curand-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-curand-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cufft-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "INFO: pip is looking at multiple versions of omegaconf to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cufft-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cudnn-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cudnn-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-runtime-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-runtime-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-nvrtc-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-nvrtc-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-cupti-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "INFO: pip is looking at multiple versions of nvidia-cuda-cupti-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nvidia-cublas-cu12 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of nvidia-cublas-cu11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of numpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "INFO: pip is looking at multiple versions of numba to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting numba==0.59.1\n",
      "  Using cached numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "INFO: pip is looking at multiple versions of nptyping to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nltk to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nlpaug to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of nfoursid to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nfoursid==1.0.1\n",
      "  Using cached nfoursid-1.0.1-py3-none-any.whl (16 kB)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx==3.2.1\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of nest-asyncio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting nest-asyncio==1.6.0\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "INFO: pip is looking at multiple versions of murmurhash to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of multidict to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multidict==6.0.5\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "INFO: pip is looking at multiple versions of msgpack to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of mpmath to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting mpmath==1.3.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "INFO: pip is looking at multiple versions of model-index to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of mlforecast to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of mdurl to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of matplotlib-inline to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib-inline==0.1.6\n",
      "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting matplotlib==3.8.3\n",
      "  Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting MarkupSafe==2.1.5\n",
      "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of markdown-it-py to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of markdown to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of mako to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lunardate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting lunardate==0.2.2\n",
      "  Using cached lunardate-0.2.2-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llvmlite==0.42.0\n",
      "  Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "INFO: pip is looking at multiple versions of lit to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lightning-utilities to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting lightning-utilities==0.11.0\n",
      "  Using cached lightning_utilities-0.11.0-py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of lightning-cloud to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lightning to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lightgbm to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of lazy-loader to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of langcodes to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of kiwisolver to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kiwisolver==1.4.5\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of jupyter-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_core==5.7.2\n",
      "  Using cached jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "INFO: pip is looking at multiple versions of jupyter-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jupyter_client==8.6.1\n",
      "  Using cached jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
      "INFO: pip is looking at multiple versions of jsonschema to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of joblib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting joblib==1.3.2\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "INFO: pip is looking at multiple versions of jmespath to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Jinja2==3.1.3\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of jedi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jedi==0.19.1\n",
      "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "INFO: pip is looking at multiple versions of itsdangerous to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of ipython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipython==8.22.2\n",
      "  Using cached ipython-8.22.2-py3-none-any.whl (811 kB)\n",
      "INFO: pip is looking at multiple versions of ipykernel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipykernel==6.29.3\n",
      "  Using cached ipykernel-6.29.3-py3-none-any.whl (117 kB)\n",
      "INFO: pip is looking at multiple versions of inquirer to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of imageio to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of idna to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting idna==3.6\n",
      "  Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "INFO: pip is looking at multiple versions of hyperopt to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of holidays to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting holidays==0.45\n",
      "  Using cached holidays-0.45-py3-none-any.whl (932 kB)\n",
      "INFO: pip is looking at multiple versions of h11 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of greenlet to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of graphviz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting graphviz==0.20.2\n",
      "  Using cached graphviz-0.20.2-py3-none-any.whl (47 kB)\n",
      "INFO: pip is looking at multiple versions of gpustat to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gluonts to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of gdown to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fugue-sql-antlr to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fugue-sql-antlr==0.2.0\n",
      "  Using cached fugue-sql-antlr-0.2.0.tar.gz (154 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of fugue to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fugue==0.8.7\n",
      "  Using cached fugue-0.8.7-py3-none-any.whl (279 kB)\n",
      "INFO: pip is looking at multiple versions of fsspec to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fs==2.4.16\n",
      "  Using cached fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "INFO: pip is looking at multiple versions of frozenlist to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting frozenlist==1.4.1\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "INFO: pip is looking at multiple versions of fugue-sql-antlr to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting fonttools==4.50.0\n",
      "  Using cached fonttools-4.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "INFO: pip is looking at multiple versions of filelock to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting filelock==3.13.1\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "INFO: pip is looking at multiple versions of fastprogress to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fastdownload to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fastcore to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of fastai to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of executing to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting executing==2.0.1\n",
      "  Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of exceptiongroup to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting exceptiongroup==1.2.0\n",
      "  Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "INFO: pip is looking at multiple versions of evaluate to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of editor to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of distlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of dill to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of deepdiff to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting decorator==5.1.1\n",
      "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting debugpy==1.8.1\n",
      "  Using cached debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "INFO: pip is looking at multiple versions of dateutils to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of darts to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting darts==0.28.0\n",
      "  Using cached darts-0.28.0-py3-none-any.whl (846 kB)\n",
      "INFO: pip is looking at multiple versions of cython to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting Cython==3.0.9\n",
      "  Using cached Cython-3.0.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "INFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cycler==0.12.1\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "INFO: pip is looking at multiple versions of cryptography to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of croniter to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of crcmod to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting contourpy==1.2.0\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "INFO: pip is looking at multiple versions of confection to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of comm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting comm==0.2.2\n",
      "  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "INFO: pip is looking at multiple versions of colorlog to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of colorful to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cmake to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cloudpickle==3.0.0\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "INFO: pip is looking at multiple versions of cloudpathlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting charset-normalizer==3.3.2\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "INFO: pip is looking at multiple versions of cffi to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting certifi==2024.2.2\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "INFO: pip is looking at multiple versions of catboost to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting catboost==1.2.3\n",
      "  Using cached catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
      "INFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cachetools to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of botocore to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of blessed to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of beautifulsoup4 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of backoff to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-timeseries to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-tabular to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-multimodal to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-features to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-core to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon-common to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of autogluon to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting attrs==23.2.0\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "INFO: pip is looking at multiple versions of async-timeout to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting async-timeout==4.0.3\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "INFO: pip is looking at multiple versions of asttokens to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting asttokens==2.4.1\n",
      "  Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "INFO: pip is looking at multiple versions of arrow to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of appdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting appdirs==1.4.4\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "INFO: pip is looking at multiple versions of anyio to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of antlr4-python3-runtime to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of aliyun-python-sdk-kms to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of aliyun-python-sdk-core to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of alembic to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of aiosignal to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiosignal==1.3.1\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "INFO: pip is looking at multiple versions of aiohttp-cors to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of aiohttp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiohttp==3.9.3\n",
      "  Using cached aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "INFO: pip is looking at multiple versions of adagio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting adagio==0.2.4\n",
      "  Using cached adagio-0.2.4-py3-none-any.whl (26 kB)\n",
      "INFO: pip is looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Cannot install -r requirements.txt (line 161), -r requirements.txt (line 76), antlr4-python3-runtime==4.9.3 and qpd==0.4.4 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "The conflict is caused by:\n",
      "    The user requested antlr4-python3-runtime==4.9.3\n",
      "    fugue-sql-antlr 0.2.0 depends on antlr4-python3-runtime<4.12\n",
      "    omegaconf 2.2.3 depends on antlr4-python3-runtime==4.9.*\n",
      "    qpd 0.4.4 depends on antlr4-python3-runtime<4.12 and >=4.11.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trial\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import holidays\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from optuna.trial import Trial\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 버전 : 3.10.13 (main, Mar 21 2024, 11:48:51) [GCC 11.4.0]\n",
      "pandas 버전 : 2.2.1\n",
      "numpy 버전 : 1.26.4\n",
      "sklearn 버전 : 1.4.1.post1\n",
      "xgboost 버전 확인 : 2.0.3\n",
      "catboost 버전 : 1.2.3\n",
      "optuna 버전 : 3.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"파이썬 버전 : {sys.version}\")\n",
    "print(f\"pandas 버전 : {pd.__version__}\")\n",
    "print(f\"numpy 버전 : {np.__version__}\")\n",
    "print(f\"sklearn 버전 : {sklearn.__version__}\")\n",
    "print(f\"xgboost 버전 확인 : {xgboost.__version__}\")\n",
    "print(f\"catboost 버전 : {catboost.__version__}\")\n",
    "print(f\"optuna 버전 : {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(2024) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/train.csv')\n",
    "test = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/test.csv')\n",
    "international_data = pd.read_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/international_trade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>기간</th>\n",
       "      <th>품목명</th>\n",
       "      <th>수출 중량</th>\n",
       "      <th>수출 금액</th>\n",
       "      <th>수입 중량</th>\n",
       "      <th>수입 금액</th>\n",
       "      <th>무역수지</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01</td>\n",
       "      <td>토마토(신선한 것이나 냉장한 것으로 한정한다)</td>\n",
       "      <td>356571</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01</td>\n",
       "      <td>양파</td>\n",
       "      <td>821330</td>\n",
       "      <td>222</td>\n",
       "      <td>4003206</td>\n",
       "      <td>1118</td>\n",
       "      <td>-896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01</td>\n",
       "      <td>쪽파</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>93405</td>\n",
       "      <td>128</td>\n",
       "      <td>-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01</td>\n",
       "      <td>꽃양배추와 브로콜리(broccoli)</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>638913</td>\n",
       "      <td>563</td>\n",
       "      <td>-562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01</td>\n",
       "      <td>방울다다기 양배추</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7580</td>\n",
       "      <td>38</td>\n",
       "      <td>-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>2023-02</td>\n",
       "      <td>포포(papaw)[파파야(papaya)]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23830</td>\n",
       "      <td>71</td>\n",
       "      <td>-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2023-02</td>\n",
       "      <td>사과</td>\n",
       "      <td>135165</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>2023-02</td>\n",
       "      <td>배</td>\n",
       "      <td>2206012</td>\n",
       "      <td>5411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>2023-02</td>\n",
       "      <td>신 체리[프루너스 체라서스(Prunus cerasus)]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>2023-02</td>\n",
       "      <td>자두</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           기간                              품목명    수출 중량  수출 금액    수입 중량  \\\n",
       "0     2019-01        토마토(신선한 것이나 냉장한 것으로 한정한다)   356571    990        0   \n",
       "1     2019-01                               양파   821330    222  4003206   \n",
       "2     2019-01                               쪽파       60      1    93405   \n",
       "3     2019-01             꽃양배추와 브로콜리(broccoli)      160      1   638913   \n",
       "4     2019-01                        방울다다기 양배추        0      0     7580   \n",
       "...       ...                              ...      ...    ...      ...   \n",
       "1269  2023-02           포포(papaw)[파파야(papaya)]        0      0    23830   \n",
       "1270  2023-02                               사과   135165    351        0   \n",
       "1271  2023-02                                배  2206012   5411        1   \n",
       "1272  2023-02  신 체리[프루너스 체라서스(Prunus cerasus)]        5      0        0   \n",
       "1273  2023-02                               자두        0      0        2   \n",
       "\n",
       "      수입 금액  무역수지  \n",
       "0         0   990  \n",
       "1      1118  -896  \n",
       "2       128  -127  \n",
       "3       563  -562  \n",
       "4        38   -38  \n",
       "...     ...   ...  \n",
       "1269     71   -71  \n",
       "1270      0   351  \n",
       "1271      0  5411  \n",
       "1272      0     0  \n",
       "1273      0     0  \n",
       "\n",
       "[1274 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "international_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품목명\n",
      "감귤                                                                               50\n",
      "포포(papaw)[파파야(papaya)]                                                           50\n",
      "레몬[시트러스 리몬(Citrus limon)ㆍ시트러스 리머늄(Citrus limonum)]                               50\n",
      "그레이프프루트(grapefruit)와 포멜로(pomelo)                                                 50\n",
      "오렌지                                                                              50\n",
      "망고(mango)                                                                        50\n",
      "파인애플                                                                             50\n",
      "무화과                                                                              50\n",
      "대추야자                                                                             50\n",
      "사과                                                                               50\n",
      "오이류(신선한 것이나 냉장한 것으로 한정한다)                                                        50\n",
      "당근                                                                               50\n",
      "배                                                                                50\n",
      "결구(結球) 상추                                                                        50\n",
      "양배추                                                                              50\n",
      "방울다다기 양배추                                                                        50\n",
      "꽃양배추와 브로콜리(broccoli)                                                             50\n",
      "수박                                                                               49\n",
      "망고스틴(mangosteen)                                                                 42\n",
      "양파                                                                               42\n",
      "자두                                                                               39\n",
      "토마토(신선한 것이나 냉장한 것으로 한정한다)                                                        36\n",
      "쪽파                                                                               36\n",
      "콩[비그나(Vigna)속ㆍ파세러스(Phaseolus)속)]                                                 25\n",
      "구아바(guava)                                                                       23\n",
      "복숭아[넥터린(nectarine)을 포함한다]                                                        23\n",
      "위트루프 치커리(Witloof chicory)[시코리엄 인티부스 변종 포리오섬(Cichorium intybus var. foliosum)]    22\n",
      "신 체리[프루너스 체라서스(Prunus cerasus)]                                                  16\n",
      "살구                                                                               15\n",
      "방울토마토                                                                            14\n",
      "샬롯(shallot)                                                                      14\n",
      "완두[피섬 새티범(Pisum sativum)]                                                        11\n",
      "참외                                                                               11\n",
      "순무                                                                                6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(international_data['품목명'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['토마토(신선한 것이나 냉장한 것으로 한정한다)' '양파' '쪽파' '꽃양배추와 브로콜리(broccoli)' '방울다다기 양배추'\n",
      " '양배추' '결구(結球) 상추'\n",
      " '위트루프 치커리(Witloof chicory)[시코리엄 인티부스 변종 포리오섬(Cichorium intybus var. foliosum)]'\n",
      " '당근' '오이류(신선한 것이나 냉장한 것으로 한정한다)' '콩[비그나(Vigna)속ㆍ파세러스(Phaseolus)속)]'\n",
      " '대추야자' '무화과' '파인애플' '망고(mango)' '망고스틴(mangosteen)' '오렌지' '감귤'\n",
      " '그레이프프루트(grapefruit)와 포멜로(pomelo)'\n",
      " '레몬[시트러스 리몬(Citrus limon)ㆍ시트러스 리머늄(Citrus limonum)]' '수박'\n",
      " '포포(papaw)[파파야(papaya)]' '사과' '배' '자두' '완두[피섬 새티범(Pisum sativum)]'\n",
      " '구아바(guava)' '살구' '신 체리[프루너스 체라서스(Prunus cerasus)]'\n",
      " '복숭아[넥터린(nectarine)을 포함한다]' '순무' '방울토마토' '샬롯(shallot)' '참외']\n"
     ]
    }
   ],
   "source": [
    "print(international_data['품목명'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_dict = {\"TG\": \"감귤\", \"BC\": \"꽃양배추와 브로콜리(broccoli)\", \"RD\": None, \"CR\": \"당근\", \"CB\": \"양배추\"} # RD: 무는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['기간', '품목명', '수출 중량', '수출 금액', '수입 중량', '수입 금액', '무역수지'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "international_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_names = {\"기간\": \"timestamp\", \"품목명\": \"item\", \"수출 중량\": \"export_weight\", \"수출 금액\": \"export_amount\", \"수입 중량\": \"import_weight\", \"수입 금액\": \"import_amount\", \"무역수지\": \"trade_profit\"}\n",
    "international_data.rename(columns=new_column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "international_data['timestamp'] = pd.to_datetime(international_data['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(international_data.timestamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_type(type_):\n",
    "    result = None\n",
    "    for key, value in relevant_dict.items():\n",
    "            if value == type_:\n",
    "                result = key\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "international_data['item'] = international_data.apply(lambda x: change_type(x['item']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1274, 7)\n",
      "(1246, 7)\n"
     ]
    }
   ],
   "source": [
    "# data leakage를 피하기 위해 international_data는 2023년 1월분까지만 사용\n",
    "print(international_data.shape)\n",
    "international_data = international_data.loc[international_data.timestamp < pd.to_datetime(\"2023-02-01\"), ]\n",
    "print(international_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136475/2630015994.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.15734056  0.63386664 -0.20819682 ...  1.27812049 -0.20825321\n",
      " -0.20825834]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])\n",
      "/tmp/ipykernel_136475/2630015994.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.36833914 -0.08320562 -0.21314233 ...  2.27270565 -0.21373028\n",
      " -0.21373028]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])\n",
      "/tmp/ipykernel_136475/2630015994.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.34081366  0.73900235 -0.3156188  ... -0.34081366 -0.34081366\n",
      " -0.34081258]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])\n",
      "/tmp/ipykernel_136475/2630015994.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.26385557 -0.07424363 -0.24214687 ... -0.26385557 -0.26385557\n",
      " -0.26385557]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])\n",
      "/tmp/ipykernel_136475/2630015994.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.3505804  0.0475911  0.17113233 ... 0.87093158 0.19153511 0.19153511]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]] = scaler.fit_transform(international_data.loc[:, [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item</th>\n",
       "      <th>export_weight</th>\n",
       "      <th>export_amount</th>\n",
       "      <th>import_weight</th>\n",
       "      <th>import_amount</th>\n",
       "      <th>trade_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.157341</td>\n",
       "      <td>0.368339</td>\n",
       "      <td>-0.340814</td>\n",
       "      <td>-0.263856</td>\n",
       "      <td>0.350580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.633867</td>\n",
       "      <td>-0.083206</td>\n",
       "      <td>0.739002</td>\n",
       "      <td>-0.074244</td>\n",
       "      <td>0.047591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.208197</td>\n",
       "      <td>-0.213142</td>\n",
       "      <td>-0.315619</td>\n",
       "      <td>-0.242147</td>\n",
       "      <td>0.171132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>BC</td>\n",
       "      <td>-0.208094</td>\n",
       "      <td>-0.213142</td>\n",
       "      <td>-0.168475</td>\n",
       "      <td>-0.168371</td>\n",
       "      <td>0.101249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.208258</td>\n",
       "      <td>-0.213730</td>\n",
       "      <td>-0.338769</td>\n",
       "      <td>-0.257411</td>\n",
       "      <td>0.185430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.208258</td>\n",
       "      <td>-0.213730</td>\n",
       "      <td>-0.337957</td>\n",
       "      <td>-0.258089</td>\n",
       "      <td>0.186073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.094759</td>\n",
       "      <td>-0.043225</td>\n",
       "      <td>-0.340814</td>\n",
       "      <td>-0.263856</td>\n",
       "      <td>0.238124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>1.278120</td>\n",
       "      <td>2.272706</td>\n",
       "      <td>-0.340814</td>\n",
       "      <td>-0.263856</td>\n",
       "      <td>0.870932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.208253</td>\n",
       "      <td>-0.213730</td>\n",
       "      <td>-0.340814</td>\n",
       "      <td>-0.263856</td>\n",
       "      <td>0.191535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.208258</td>\n",
       "      <td>-0.213730</td>\n",
       "      <td>-0.340813</td>\n",
       "      <td>-0.263856</td>\n",
       "      <td>0.191535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1246 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  item  export_weight  export_amount  import_weight  \\\n",
       "0    2019-01-01  None       0.157341       0.368339      -0.340814   \n",
       "1    2019-01-01  None       0.633867      -0.083206       0.739002   \n",
       "2    2019-01-01  None      -0.208197      -0.213142      -0.315619   \n",
       "3    2019-01-01    BC      -0.208094      -0.213142      -0.168475   \n",
       "4    2019-01-01  None      -0.208258      -0.213730      -0.338769   \n",
       "...         ...   ...            ...            ...            ...   \n",
       "1241 2023-01-01  None      -0.208258      -0.213730      -0.337957   \n",
       "1242 2023-01-01  None      -0.094759      -0.043225      -0.340814   \n",
       "1243 2023-01-01  None       1.278120       2.272706      -0.340814   \n",
       "1244 2023-01-01  None      -0.208253      -0.213730      -0.340814   \n",
       "1245 2023-01-01  None      -0.208258      -0.213730      -0.340813   \n",
       "\n",
       "      import_amount  trade_profit  \n",
       "0         -0.263856      0.350580  \n",
       "1         -0.074244      0.047591  \n",
       "2         -0.242147      0.171132  \n",
       "3         -0.168371      0.101249  \n",
       "4         -0.257411      0.185430  \n",
       "...             ...           ...  \n",
       "1241      -0.258089      0.186073  \n",
       "1242      -0.263856      0.238124  \n",
       "1243      -0.263856      0.870932  \n",
       "1244      -0.263856      0.191535  \n",
       "1245      -0.263856      0.191535  \n",
       "\n",
       "[1246 rows x 7 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "international_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_all(train, test):\n",
    "    print(f\"전처리 전 train 크기 : {train.shape}\")\n",
    "    print(f\"전처리 전 test 크기 : {test.shape}\")\n",
    "    print(\"=================전처리 중=================\")\n",
    "\n",
    "    # 합쳐서 전처리하기\n",
    "    train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "    test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "    df = pd.concat([train,test]).reset_index(drop = True)\n",
    "    \n",
    "    df.rename(columns={'supply(kg)':'supply', 'price(원/kg)':'price'},inplace=True)\n",
    "\n",
    "    #년/월/일 추가\n",
    "    df['year']=df['timestamp'].dt.year\n",
    "    df['month']=df['timestamp'].dt.month\n",
    "    df['day']=df['timestamp'].dt.day\n",
    "\n",
    "    #요일 추가\n",
    "    df['week_day']=df['timestamp'].dt.weekday\n",
    "\n",
    "    # 년-월 변수 추가 : year-month의 형태, 개월단위 누적값\n",
    "    le = LabelEncoder()\n",
    "    df[\"year_month\"] = df[\"timestamp\"].map(lambda x :str(x.year) + \"-\"+str(x.month))\n",
    "\n",
    "    # 라벨 인코딩\n",
    "    df[\"year_month\"] = le.fit_transform(df[\"year_month\"])\n",
    "\n",
    "\n",
    "    # 주차 변수 추가\n",
    "    df[\"week\"] = df[\"timestamp\"].map(lambda x: datetime.datetime(x.year, x.month, x.day).isocalendar()[1])\n",
    "\n",
    "    # 주차 누적값\n",
    "    week_list=[]\n",
    "    for i in range(len(df['year'])) :\n",
    "        if df['year'][i] == 2019 :\n",
    "            week_list.append(int(df['week'][i]))\n",
    "        elif df['year'][i] == 2020 :\n",
    "            week_list.append(int(df['week'][i])+52)\n",
    "        elif df['year'][i] == 2021 :\n",
    "            week_list.append(int(df['week'][i])+52+53)\n",
    "        elif df['year'][i] == 2022 :\n",
    "            week_list.append(int(df['week'][i])+52+53+53)\n",
    "        elif df['year'][i] == 2023 :\n",
    "            week_list.append(int(df['week'][i])+52+53+53+52)\n",
    "    df['week_num']= week_list\n",
    "\n",
    "    # datetime 패키지에서 19년 12월 마지막주가 첫째주로 들어가는거 발견하여 수정\n",
    "    df.loc[df['timestamp']=='2019-12-30','week_num']=52\n",
    "    df.loc[df['timestamp']=='2019-12-31','week_num']=52\n",
    "\n",
    "\n",
    "    # 공휴일 변수 추가\n",
    "    def make_holi(x):\n",
    "        kr_holi = holidays.KR()\n",
    "\n",
    "        if x in kr_holi:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    df[\"holiday\"] = df[\"timestamp\"].map(lambda x : make_holi(x))\n",
    "\n",
    "    # 국제 무역 데이터 접합하기\n",
    "    # subsidiary_data = []\n",
    "    # for i in range(len(df)):\n",
    "    #     row = df.iloc[i, :]\n",
    "    #     item_ = row['item']\n",
    "    #     row_date = row.timestamp\n",
    "    #     target = relevant_dict[item_]\n",
    "    #     if target == None:\n",
    "    #         subsidiary_data.append([None] * 5)\n",
    "    #         continue\n",
    "    #     target_row = international_data.loc[(international_data.type == relevant_dict[\"TG\"]) & (international_data.date_year_month == row_date), [\"export_weight\", \"export_amount\", \"import_weight\", \"import_amount\", \"trade_profit\"]]\n",
    "    #     if target_row.empty:\n",
    "    #         subsidiary_data.append([None] * 5)\n",
    "    #         continue\n",
    "    #     target_row_list = target_row.values.tolist()[0]\n",
    "    #     subsidiary_data.append(target_row_list)\n",
    "\n",
    "    # subsidiary_df = pd.DataFrame(subsidiary_data)\n",
    "\n",
    "    # print(df.shape)\n",
    "    # print(subsidiary_df.shape)\n",
    "\n",
    "    # df = pd.concat([df, subsidiary_df], axis=1)\n",
    "    # df = pd.merge(df, international_data, on=[\"timestamp\", \"item\"], how=\"inner\")\n",
    "    df = pd.merge(df, international_data, on=[\"timestamp\", \"item\"], how=\"left\")\n",
    "\n",
    "    # train, test 분리하기\n",
    "    train = df[~df[\"price\"].isnull()].sort_values(\"timestamp\").reset_index(drop = True)\n",
    "    test = df[df[\"price\"].isnull()].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "    print(f\"전처리 후 train 크기 : {train.shape}\")\n",
    "    print(f\"전처리 후 test 크기 : {test.shape}\")\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 크기 : (59397, 7)\n",
      "전처리 전 test 크기 : (1092, 5)\n",
      "=================전처리 중=================\n",
      "전처리 후 train 크기 : (59397, 20)\n",
      "전처리 후 test 크기 : (1092, 20)\n"
     ]
    }
   ],
   "source": [
    "train_pre, test_pre = pre_all(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    ID  timestamp item corporation location    supply   price  \\\n",
      "0      TG_A_J_20190101 2019-01-01   TG           A        J       0.0     0.0   \n",
      "1      CB_A_S_20190101 2019-01-01   CB           A        S       0.0     0.0   \n",
      "2      RD_D_J_20190101 2019-01-01   RD           D        J       0.0     0.0   \n",
      "3      BC_D_J_20190101 2019-01-01   BC           D        J       0.0     0.0   \n",
      "4      CB_F_J_20190101 2019-01-01   CB           F        J       0.0     0.0   \n",
      "...                ...        ...  ...         ...      ...       ...     ...   \n",
      "59392  CR_E_S_20230303 2023-03-03   CR           E        S       0.0     0.0   \n",
      "59393  BC_A_S_20230303 2023-03-03   BC           A        S    3776.0  2875.0   \n",
      "59394  CB_E_J_20230303 2023-03-03   CB           E        J       0.0     0.0   \n",
      "59395  BC_D_J_20230303 2023-03-03   BC           D        J    1776.0  3059.0   \n",
      "59396  RD_F_J_20230303 2023-03-03   RD           F        J  427520.0   529.0   \n",
      "\n",
      "       year  month  day  week_day  year_month  week  week_num  holiday  \\\n",
      "0      2019      1    1         1           0     1         1        1   \n",
      "1      2019      1    1         1           0     1         1        1   \n",
      "2      2019      1    1         1           0     1         1        1   \n",
      "3      2019      1    1         1           0     1         1        1   \n",
      "4      2019      1    1         1           0     1         1        1   \n",
      "...     ...    ...  ...       ...         ...   ...       ...      ...   \n",
      "59392  2023      3    3         4          50     9       219        0   \n",
      "59393  2023      3    3         4          50     9       219        0   \n",
      "59394  2023      3    3         4          50     9       219        0   \n",
      "59395  2023      3    3         4          50     9       219        0   \n",
      "59396  2023      3    3         4          50     9       219        0   \n",
      "\n",
      "       export_weight  export_amount  import_weight  import_amount  \\\n",
      "0          -0.148413      -0.112603      -0.340814      -0.263856   \n",
      "1          -0.018933      -0.158463      -0.234051      -0.248592   \n",
      "2                NaN            NaN            NaN            NaN   \n",
      "3          -0.208094      -0.213142      -0.168475      -0.168371   \n",
      "4          -0.018933      -0.158463      -0.234051      -0.248592   \n",
      "...              ...            ...            ...            ...   \n",
      "59392            NaN            NaN            NaN            NaN   \n",
      "59393            NaN            NaN            NaN            NaN   \n",
      "59394            NaN            NaN            NaN            NaN   \n",
      "59395            NaN            NaN            NaN            NaN   \n",
      "59396            NaN            NaN            NaN            NaN   \n",
      "\n",
      "       trade_profit  \n",
      "0          0.219167  \n",
      "1          0.192178  \n",
      "2               NaN  \n",
      "3          0.101249  \n",
      "4          0.192178  \n",
      "...             ...  \n",
      "59392           NaN  \n",
      "59393           NaN  \n",
      "59394           NaN  \n",
      "59395           NaN  \n",
      "59396           NaN  \n",
      "\n",
      "[59397 rows x 20 columns]\n",
      "Index(['ID', 'timestamp', 'item', 'corporation', 'location', 'supply', 'price',\n",
      "       'year', 'month', 'day', 'week_day', 'year_month', 'week', 'week_num',\n",
      "       'holiday', 'export_weight', 'export_amount', 'import_weight',\n",
      "       'import_amount', 'trade_profit'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_pre)\n",
    "print(train_pre.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   ID  timestamp item corporation location  supply  price  \\\n",
      "0     TG_A_J_20230304 2023-03-04   TG           A        J     NaN    NaN   \n",
      "1     TG_E_S_20230304 2023-03-04   TG           E        S     NaN    NaN   \n",
      "2     BC_B_J_20230304 2023-03-04   BC           B        J     NaN    NaN   \n",
      "3     TG_E_J_20230304 2023-03-04   TG           E        J     NaN    NaN   \n",
      "4     BC_B_S_20230304 2023-03-04   BC           B        S     NaN    NaN   \n",
      "...               ...        ...  ...         ...      ...     ...    ...   \n",
      "1087  TG_A_J_20230331 2023-03-31   TG           A        J     NaN    NaN   \n",
      "1088  RD_D_J_20230331 2023-03-31   RD           D        J     NaN    NaN   \n",
      "1089  CR_D_J_20230331 2023-03-31   CR           D        J     NaN    NaN   \n",
      "1090  TG_E_J_20230331 2023-03-31   TG           E        J     NaN    NaN   \n",
      "1091  RD_F_J_20230331 2023-03-31   RD           F        J     NaN    NaN   \n",
      "\n",
      "      year  month  day  week_day  year_month  week  week_num  holiday  \\\n",
      "0     2023      3    4         5          50     9       219        0   \n",
      "1     2023      3    4         5          50     9       219        0   \n",
      "2     2023      3    4         5          50     9       219        0   \n",
      "3     2023      3    4         5          50     9       219        0   \n",
      "4     2023      3    4         5          50     9       219        0   \n",
      "...    ...    ...  ...       ...         ...   ...       ...      ...   \n",
      "1087  2023      3   31         4          50    13       223        0   \n",
      "1088  2023      3   31         4          50    13       223        0   \n",
      "1089  2023      3   31         4          50    13       223        0   \n",
      "1090  2023      3   31         4          50    13       223        0   \n",
      "1091  2023      3   31         4          50    13       223        0   \n",
      "\n",
      "      export_weight  export_amount  import_weight  import_amount  trade_profit  \n",
      "0               NaN            NaN            NaN            NaN           NaN  \n",
      "1               NaN            NaN            NaN            NaN           NaN  \n",
      "2               NaN            NaN            NaN            NaN           NaN  \n",
      "3               NaN            NaN            NaN            NaN           NaN  \n",
      "4               NaN            NaN            NaN            NaN           NaN  \n",
      "...             ...            ...            ...            ...           ...  \n",
      "1087            NaN            NaN            NaN            NaN           NaN  \n",
      "1088            NaN            NaN            NaN            NaN           NaN  \n",
      "1089            NaN            NaN            NaN            NaN           NaN  \n",
      "1090            NaN            NaN            NaN            NaN           NaN  \n",
      "1091            NaN            NaN            NaN            NaN           NaN  \n",
      "\n",
      "[1092 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. TG 외 품목들\n",
    "### 0-1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train의 컬럼 : Index(['ID', 'timestamp', 'item', 'corporation', 'location', 'supply', 'price',\n",
      "       'year', 'month', 'day', 'week_day', 'year_month', 'week', 'week_num',\n",
      "       'holiday', 'export_weight', 'export_amount', 'import_weight',\n",
      "       'import_amount', 'trade_profit'],\n",
      "      dtype='object')\n",
      "test의 컬럼 : Index(['ID', 'timestamp', 'item', 'corporation', 'location', 'supply', 'price',\n",
      "       'year', 'month', 'day', 'week_day', 'year_month', 'week', 'week_num',\n",
      "       'holiday', 'export_weight', 'export_amount', 'import_weight',\n",
      "       'import_amount', 'trade_profit'],\n",
      "      dtype='object')\n",
      "Index(['ID', 'timestamp', 'price', 'year', 'month', 'day', 'week_day',\n",
      "       'year_month', 'week', 'week_num', 'holiday', 'export_weight',\n",
      "       'export_amount', 'import_weight', 'import_amount', 'trade_profit',\n",
      "       'item_BC', 'item_CB', 'item_CR', 'item_RD', 'corporation_A',\n",
      "       'corporation_B', 'corporation_C', 'corporation_D', 'corporation_E',\n",
      "       'corporation_F', 'location_J', 'location_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## 전처리\n",
    "\n",
    "# 극 이상치 제거\n",
    "tg_idx = train_pre[(train_pre[\"item\"]==\"TG\") & (train_pre[\"price\"]>20000)].index\n",
    "rd_idx = train_pre[(train_pre[\"item\"]==\"RD\") & (train_pre[\"price\"]>5000)].index\n",
    "bc_idx = train_pre[(train_pre[\"item\"]==\"BC\") & (train_pre[\"price\"]>8000)].index\n",
    "cb_idx = train_pre[(train_pre[\"item\"]==\"CB\") & (train_pre[\"price\"]>2300)].index\n",
    "\n",
    "train_pre.loc[tg_idx,\"price\"] = train_pre[(train_pre[\"item\"]==\"TG\") & (train_pre[\"price\"]!=0)][\"price\"].mean()\n",
    "train_pre.loc[rd_idx,\"price\"] = train_pre[(train_pre[\"item\"]==\"RD\") & (train_pre[\"price\"]!=0)][\"price\"].mean()\n",
    "train_pre.loc[bc_idx,\"price\"] = train_pre[(train_pre[\"item\"]==\"BC\") & (train_pre[\"price\"]!=0)][\"price\"].mean()\n",
    "train_pre.loc[cb_idx,\"price\"] = train_pre[(train_pre[\"item\"]==\"CB\") & (train_pre[\"price\"]!=0)][\"price\"].mean()\n",
    "\n",
    "\n",
    "# 감귤이 아닌것\n",
    "print(f\"train의 컬럼 : {train_pre.columns}\")\n",
    "print(f\"test의 컬럼 : {test_pre.columns}\")\n",
    "\n",
    "train_notg = train_pre[train_pre[\"item\"] !=\"TG\"]\n",
    "test_notg = test_pre[test_pre[\"item\"] != \"TG\"]\n",
    "\n",
    "\n",
    "#인코딩\n",
    "Xy = pd.get_dummies(train_notg.sort_values(by = [\"timestamp\"]).reset_index(drop=True).drop(columns = [\"supply\"]), columns = [\"item\",\"corporation\",\"location\"])\n",
    "answer_notg = pd.get_dummies(test_notg.drop(columns = [\"timestamp\",\"supply\",\"price\"]), columns = [ \"item\",\"corporation\",\"location\"])\n",
    "print(Xy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vote(trial: Trial, model_1, model_2, x, y, eval_metric):\n",
    "    \"\"\"\n",
    "    Optuna의 하이퍼파라미터 튜닝을 위한 목적 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: Optuna의 Trial 객체\n",
    "    - model: 튜닝할 머신러닝 모델\n",
    "    - x: 입력 데이터\n",
    "    - y: 타겟 데이터\n",
    "    - eval_metric: 모델을 평가하기 위한 메트릭\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델에 맞는 하이퍼파라미터 범위를 정의합니다.\n",
    "    # cat = CatBoostRegressor(random_state = 2024, \n",
    "    #                             n_estimators = n_estimators, \n",
    "    #                             learning_rate = lrs, \n",
    "    #                             depth = max_depths, \n",
    "    #                             l2_leaf_reg = l2_leaf_reg,\n",
    "    #                             metric_period = 1000)\n",
    "    # xgb = XGBRegressor(n_estimators = 1000,\n",
    "    #                    random_state = 2024,\n",
    "    #                    learning_rate = 0.01,\n",
    "    #                    max_depth = 10)\n",
    "    params_cat = {\n",
    "        'random_state': 2024,\n",
    "        'metric_period': 1000,\n",
    "        'thread_count': -1,\n",
    "        # 'criterion': trial.suggest_categorical('criterion', ['squared_error', 'absolute_error']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, step=0.01),\n",
    "        'depth': trial.suggest_int('depth', 5, 15, step=1),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 5, step=1),\n",
    "        # 'max_features': trial.suggest_float('max_features', 0.6, 0.9, step=0.1),\n",
    "    }\n",
    "\n",
    "    params_xgb = {\n",
    "        'random_state': 2024,\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, step=0.01),\n",
    "        'max_depth': trial.suggest_int('depth', 5, 15, step=1),\n",
    "    }\n",
    "\n",
    "    params_voting = {\n",
    "        'weights': [trial.suggest_float('learning_rate', 0, 1, step=0.1), trial.suggest_float('learning_rate', 0, 1, step=0.1)]\n",
    "    }\n",
    "\n",
    "    # 데이터 프레임이나 시리즈 형태의 x와 y를 numpy 배열로 변환합니다.\n",
    "    x_np = x.values if isinstance(x, pd.DataFrame) else x    \n",
    "    y_np = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "    results = dict()\n",
    "    \n",
    "    # 5-Fold Cross Validation을 정의합니다.\n",
    "    # fold = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "    \n",
    "    # 각 Fold에 대해 모델을 학습하고 평가합니다.\n",
    "    # for i, (train_idx, test_idx) in enumerate(fold.split(x, y)):\n",
    "    years = [2019, 2020, 2021, 2022]\n",
    "    for i, year in enumerate(years):\n",
    "        filtered_df = x[(x['year'] == year) & (x['month'] == 3) & (x['day'].between(4, 31))]\n",
    "        train_idx = x.index.difference(filtered_df.index)\n",
    "        test_idx = filtered_df.index\n",
    "\n",
    "        x_train, y_train = x_np[train_idx], y_np[train_idx]\n",
    "        x_test, y_test = x_np[test_idx], y_np[test_idx]\n",
    "        \n",
    "        # 현재의 하이퍼파라미터 세트로 모델을 생성하고 학습합니다.\n",
    "        # voting\n",
    "        cat = model_1(**params_cat)\n",
    "        xgb = model_2(**params_xgb)\n",
    "        fold_model = VotingRegressor(\n",
    "            estimators =[(\"cat\",cat), (\"xgb\", xgb)],\n",
    "            voting='soft',\n",
    "            **params_voting,\n",
    "        )\n",
    "\n",
    "        fold_model.fit(x_train, y_train)\n",
    "        fold_pred = fold_model.predict(x_test)\n",
    "        \n",
    "        # 음수 추론값 0으로 치환\n",
    "        for idx in range(len(fold_pred)):\n",
    "            if fold_pred[idx]<0:\n",
    "                fold_pred[idx]= 0\n",
    "\n",
    "        \n",
    "        # 해당 Fold의 평가 결과를 저장합니다.\n",
    "        fold_error = eval_metric(y_test, fold_pred)\n",
    "        \n",
    "        results[i] = {\n",
    "            'model': fold_model, \n",
    "            'error': fold_error\n",
    "        }\n",
    "    \n",
    "    # 모든 Fold의 평가 결과의 평균을 반환합니다.\n",
    "    errors = [v['error'] for k, v in results.items()]\n",
    "    return np.array(errors).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최소화 방향으로 하이퍼 파라미터 학습을 위한 스터디 객체를 생성합니다.\n",
    "study_voting = optuna.create_study(direction='minimize', study_name='voting_regressor_1')\n",
    "\n",
    "# 하이퍼파라미터 튜닝을 시작합니다.\n",
    "study_voting.optimize(lambda trial: objective_vote(trial,\n",
    "                                                   CatBoostRegressor,\n",
    "                                                   XGBRegressor,\n",
    "                                                   Xy.drop(columns = [\"timestamp\", \"ID\",\"price\"]),\n",
    "                                                   Xy[\"price\"],\n",
    "                                                   mean_squared_error),\n",
    "                                                   n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 하이퍼파라미터를 출력합니다.\n",
    "print(study_voting.best_params)\n",
    "\n",
    "# # 모델에 적용시\n",
    "# model = RandomForestRegressor(**study.best_params)\n",
    "# model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 923.0041829\ttotal: 7.31ms\tremaining: 5.84s\n",
      "799:\tlearn: 368.9378603\ttotal: 4.61s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BC_B_J_20230304</td>\n",
       "      <td>2508.147215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BC_B_S_20230304</td>\n",
       "      <td>183.390632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BC_C_J_20230304</td>\n",
       "      <td>2514.466105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BC_A_S_20230304</td>\n",
       "      <td>2798.988935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BC_D_J_20230304</td>\n",
       "      <td>2909.215552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>RD_D_S_20230331</td>\n",
       "      <td>484.292780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>CR_C_J_20230331</td>\n",
       "      <td>1773.018243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>RD_D_J_20230331</td>\n",
       "      <td>444.345799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>CR_D_J_20230331</td>\n",
       "      <td>1939.259611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>RD_F_J_20230331</td>\n",
       "      <td>541.965754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID       answer\n",
       "2     BC_B_J_20230304  2508.147215\n",
       "4     BC_B_S_20230304   183.390632\n",
       "6     BC_C_J_20230304  2514.466105\n",
       "7     BC_A_S_20230304  2798.988935\n",
       "10    BC_D_J_20230304  2909.215552\n",
       "...               ...          ...\n",
       "1085  RD_D_S_20230331   484.292780\n",
       "1086  CR_C_J_20230331  1773.018243\n",
       "1088  RD_D_J_20230331   444.345799\n",
       "1089  CR_D_J_20230331  1939.259611\n",
       "1091  RD_F_J_20230331   541.965754\n",
       "\n",
       "[812 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 앙상블 모델 정의\n",
    "\n",
    "# cat = CatBoostRegressor(random_state = 2024, \n",
    "#                             n_estimators = 1000, \n",
    "#                             learning_rate = 0.01, \n",
    "#                             depth = 10,\n",
    "#                             l2_leaf_reg = 3,\n",
    "#                             metric_period = 1000)\n",
    "# cat = CatBoostRegressor(random_state = 2024, \n",
    "#                             metric_period = 1000,\n",
    "#                             **study.best_params)\n",
    "\n",
    "# xgb = XGBRegressor(n_estimators = 1000, random_state = 2024, learning_rate = 0.01, max_depth = 10)\n",
    "cat = CatBoostRegressor()\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# voting\n",
    "vote_model = VotingRegressor(\n",
    "    estimators =[(\"cat\",cat), (\"xgb\", xgb)]\n",
    ")\n",
    "\n",
    "vote_model.fit(Xy.drop(columns = [\"timestamp\", \"ID\", \"price\"]), Xy[\"price\"])\n",
    "\n",
    "pred = vote_model.predict(answer_notg.drop(columns = [\"ID\"]))\n",
    "for idx in range(len(pred)):\n",
    "    if pred[idx]<0:\n",
    "        pred[idx]= 0\n",
    "answer_notg[\"answer\"] = pred\n",
    "\n",
    "answer_notg[[\"ID\",\"answer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TG (1)\n",
    "### 1-1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전 train 크기 : (59397, 7)\n",
      "전처리 전 test 크기 : (1092, 5)\n",
      "=================전처리 중=================\n",
      "전처리 후 train 크기 : (59397, 20)\n",
      "전처리 후 test 크기 : (1092, 20)\n",
      "train의 컬럼 : Index(['ID', 'timestamp', 'price', 'year', 'month', 'day', 'week_day',\n",
      "       'year_month', 'week', 'week_num', 'holiday', 'export_weight',\n",
      "       'export_amount', 'import_weight', 'import_amount', 'trade_profit',\n",
      "       'item_TG', 'corporation_A', 'corporation_B', 'corporation_C',\n",
      "       'corporation_D', 'corporation_E', 'location_J', 'location_S'],\n",
      "      dtype='object')\n",
      "test의 컬럼 : Index(['ID', 'year', 'month', 'day', 'week_day', 'year_month', 'week',\n",
      "       'week_num', 'holiday', 'export_weight', 'export_amount',\n",
      "       'import_weight', 'import_amount', 'trade_profit', 'item_TG',\n",
      "       'corporation_A', 'corporation_B', 'corporation_C', 'corporation_D',\n",
      "       'corporation_E', 'location_J', 'location_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_pre, test_pre = pre_all(train, test)\n",
    "\n",
    "# 공휴일이지만 안쉬는 날 제외하기\n",
    "no_holi = list(train_pre[(train_pre[\"item\"] ==\"TG\") &(train_pre[\"holiday\"]==1) & (train_pre[\"price\"]!=0)].groupby(\"timestamp\").count().reset_index()[\"timestamp\"])\n",
    "noholi_idx = train_pre[train_pre[\"timestamp\"].isin(no_holi)][\"holiday\"].index\n",
    "for idx in noholi_idx:\n",
    "    train_pre.loc[idx, \"holiday\"] = 0\n",
    "\n",
    "# train 및 test 시간 순서로 정렬하기\n",
    "train_tg = train_pre[train_pre[\"item\"] == \"TG\"].sort_values(by = [\"timestamp\"]).reset_index(drop= True)\n",
    "test_tg = test_pre[test_pre[\"item\"] == \"TG\"].sort_values(by = [\"timestamp\"]).reset_index(drop= True)\n",
    "\n",
    "Xy = pd.get_dummies(train_tg, columns = [ \"item\",\"corporation\",\"location\"]).drop(columns = [\"supply\"])\n",
    "answer_tg1 = pd.get_dummies(test_tg, columns = [ \"item\",\"corporation\",\"location\"]).drop(columns = [\"timestamp\",\"supply\",\"price\"])\n",
    "print(f\"train의 컬럼 : {Xy.columns}\")\n",
    "print(f\"test의 컬럼 : {answer_tg1.columns}\")\n",
    "Xy[\"price\"] = np.sqrt(Xy[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 모델링 & 훈련 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 30.6073679\ttotal: 5.04ms\tremaining: 4.02s\n",
      "799:\tlearn: 14.9303818\ttotal: 3.22s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TG_A_J_20230304</td>\n",
       "      <td>2735.490800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG_E_S_20230304</td>\n",
       "      <td>3380.409401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TG_E_J_20230304</td>\n",
       "      <td>593.513615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TG_D_S_20230304</td>\n",
       "      <td>3636.158665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TG_D_J_20230304</td>\n",
       "      <td>177.123287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>TG_D_J_20230331</td>\n",
       "      <td>1665.146813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>TG_D_S_20230331</td>\n",
       "      <td>5173.276573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>TG_A_S_20230331</td>\n",
       "      <td>5553.466512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>TG_E_S_20230331</td>\n",
       "      <td>4919.463870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>TG_E_J_20230331</td>\n",
       "      <td>1654.628353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID       answer\n",
       "0    TG_A_J_20230304  2735.490800\n",
       "1    TG_E_S_20230304  3380.409401\n",
       "2    TG_E_J_20230304   593.513615\n",
       "3    TG_D_S_20230304  3636.158665\n",
       "4    TG_D_J_20230304   177.123287\n",
       "..               ...          ...\n",
       "275  TG_D_J_20230331  1665.146813\n",
       "276  TG_D_S_20230331  5173.276573\n",
       "277  TG_A_S_20230331  5553.466512\n",
       "278  TG_E_S_20230331  4919.463870\n",
       "279  TG_E_J_20230331  1654.628353\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # 모델 정의\n",
    "# cat = CatBoostRegressor(random_state = 2024, \n",
    "#                             n_estimators = 1000, \n",
    "#                             learning_rate = 0.01, \n",
    "#                             depth = 10,\n",
    "#                             l2_leaf_reg = 3,\n",
    "#                             metric_period = 1000)\n",
    "cat = CatBoostRegressor(random_state = 2024, \n",
    "                            metric_period = 1000,\n",
    "                            **study.best_params)\n",
    "xgb = XGBRegressor(n_estimators = 1000, random_state = 2024, learning_rate = 0.01, max_depth = 10)\n",
    "\n",
    "\n",
    "# voting\n",
    "vote_model = VotingRegressor(\n",
    "    estimators =[(\"cat\",cat), (\"xgb\", xgb)]\n",
    ")\n",
    "\n",
    "vote_model.fit(Xy.drop(columns = [\"timestamp\", \"ID\",\"price\"]), Xy[\"price\"])\n",
    "\n",
    "pred = vote_model.predict(answer_tg1.drop(columns = [\"ID\"]))\n",
    "for idx in range(len(pred)):\n",
    "    if pred[idx]<0:\n",
    "        pred[idx]= 0\n",
    "answer_tg1[\"answer\"] = np.power(pred,2)\n",
    "\n",
    "answer_tg1[[\"ID\",\"answer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TG (2)\n",
    "- 일반화를 위한 추가 모델링\n",
    "### 4-1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'timestamp', 'price', 'year', 'month', 'day', 'week_day',\n",
      "       'year_month', 'week', 'week_num', 'holiday', 'export_weight',\n",
      "       'export_amount', 'import_weight', 'import_amount', 'trade_profit',\n",
      "       'corporation_A', 'corporation_B', 'corporation_C', 'corporation_D',\n",
      "       'corporation_E', 'location_J', 'location_S'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_tg2 = train_pre[train_pre[\"item\"] ==\"TG\"]\n",
    "test_tg2 = test_pre[test_pre[\"item\"] == \"TG\"]\n",
    "\n",
    "Xy2 = pd.get_dummies(train_tg2.sort_values(by = [\"timestamp\", \"corporation\",\"location\"]).reset_index(drop=True).drop(columns = [\"item\",\"supply\"]), columns = [ \"corporation\",\"location\"])\n",
    "answer_tg2 = pd.get_dummies(test_tg2.drop(columns = [\"timestamp\",\"supply\",\"price\",\"item\"]), columns = [ \"corporation\",\"location\"])\n",
    "print(Xy2.columns)\n",
    "\n",
    "# 종속변수 루트값\n",
    "Xy2[\"price\"] = np.sqrt(Xy2[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. 모델링 & 훈련 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_cat(trial: Trial, model, x, y, eval_metric):\n",
    "    \"\"\"\n",
    "    Optuna의 하이퍼파라미터 튜닝을 위한 목적 함수\n",
    "    \n",
    "    Parameters:\n",
    "    - trial: Optuna의 Trial 객체\n",
    "    - model: 튜닝할 머신러닝 모델\n",
    "    - x: 입력 데이터\n",
    "    - y: 타겟 데이터\n",
    "    - eval_metric: 모델을 평가하기 위한 메트릭\n",
    "    \"\"\"\n",
    "    \n",
    "    # 모델에 맞는 하이퍼파라미터 범위를 정의합니다.\n",
    "    # cat = CatBoostRegressor(random_state = 2024, \n",
    "    #                             n_estimators = n_estimators, \n",
    "    #                             learning_rate = lrs, \n",
    "    #                             depth = max_depths, \n",
    "    #                             l2_leaf_reg = l2_leaf_reg,\n",
    "    #                             metric_period = 1000)\n",
    "    params = {\n",
    "        'random_state': 2024,\n",
    "        'thread_count': -1,\n",
    "        # 'criterion': trial.suggest_categorical('criterion', ['squared_error', 'absolute_error']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 1000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.05, step=0.01),\n",
    "        'depth': trial.suggest_int('depth', 5, 15, step=1),\n",
    "        'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 5, step=1),\n",
    "        # 'max_features': trial.suggest_float('max_features', 0.6, 0.9, step=0.1),\n",
    "    }\n",
    "\n",
    "    # 데이터 프레임이나 시리즈 형태의 x와 y를 numpy 배열로 변환합니다.\n",
    "    x_np = x.values if isinstance(x, pd.DataFrame) else x    \n",
    "    y_np = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "    results = dict()\n",
    "    \n",
    "    # 5-Fold Cross Validation을 정의합니다.\n",
    "    # fold = KFold(n_splits=5, shuffle=True, random_state=2024)\n",
    "    \n",
    "    # 각 Fold에 대해 모델을 학습하고 평가합니다.\n",
    "    # for i, (train_idx, test_idx) in enumerate(fold.split(x, y)):\n",
    "    years = [2019, 2020, 2021, 2022]\n",
    "    for i, year in enumerate(years):\n",
    "        filtered_df = x[(x['year'] == year) & (x['month'] == 3) & (x['day'].between(4, 31))]\n",
    "        train_idx = x.index.difference(filtered_df.index)\n",
    "        test_idx = filtered_df.index\n",
    "\n",
    "        x_train, y_train = x_np[train_idx], y_np[train_idx]\n",
    "        x_test, y_test = x_np[test_idx], y_np[test_idx]\n",
    "        \n",
    "        # 현재의 하이퍼파라미터 세트로 모델을 생성하고 학습합니다.\n",
    "        fold_model = model(**params)  \n",
    "        fold_model.fit(x_train, y_train)\n",
    "        fold_pred = fold_model.predict(x_test)\n",
    "        \n",
    "        # 해당 Fold의 평가 결과를 저장합니다.\n",
    "        fold_error = eval_metric(y_test, fold_pred)\n",
    "        \n",
    "        results[i] = {\n",
    "            'model': fold_model, \n",
    "            'error': fold_error\n",
    "        }\n",
    "    \n",
    "    # 모든 Fold의 평가 결과의 평균을 반환합니다.\n",
    "    errors = [v['error'] for k, v in results.items()]\n",
    "    return np.array(errors).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 30.6122496\ttotal: 7.17ms\tremaining: 5.73s\n",
      "799:\tlearn: 14.9019513\ttotal: 3.53s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TG_A_J_20230304</td>\n",
       "      <td>2817.542087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG_E_S_20230304</td>\n",
       "      <td>3409.830275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TG_E_J_20230304</td>\n",
       "      <td>1019.689881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TG_D_S_20230304</td>\n",
       "      <td>3646.742081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TG_D_J_20230304</td>\n",
       "      <td>576.703029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>TG_D_S_20230331</td>\n",
       "      <td>5132.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>TG_A_S_20230331</td>\n",
       "      <td>5425.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>TG_E_S_20230331</td>\n",
       "      <td>4941.007349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>TG_A_J_20230331</td>\n",
       "      <td>5020.509523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>TG_E_J_20230331</td>\n",
       "      <td>2317.426279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID       answer\n",
       "0     TG_A_J_20230304  2817.542087\n",
       "1     TG_E_S_20230304  3409.830275\n",
       "3     TG_E_J_20230304  1019.689881\n",
       "5     TG_D_S_20230304  3646.742081\n",
       "8     TG_D_J_20230304   576.703029\n",
       "...               ...          ...\n",
       "1074  TG_D_S_20230331  5132.000731\n",
       "1077  TG_A_S_20230331  5425.052000\n",
       "1079  TG_E_S_20230331  4941.007349\n",
       "1087  TG_A_J_20230331  5020.509523\n",
       "1090  TG_E_J_20230331  2317.426279\n",
       "\n",
       "[280 rows x 2 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 정의 및 훈련 예측\n",
    "n_estimators =1000\n",
    "lrs = 0.05\n",
    "max_depths = 10\n",
    "l2_leaf_reg = 3\n",
    "\n",
    "# cat = CatBoostRegressor(random_state = 2024, \n",
    "#                                 n_estimators = n_estimators, \n",
    "#                                 learning_rate = lrs, \n",
    "#                                 depth = max_depths, \n",
    "#                                 l2_leaf_reg = l2_leaf_reg,\n",
    "#                                 metric_period = 1000)\n",
    "cat = CatBoostRegressor(random_state = 2024, \n",
    "                            metric_period = 1000,\n",
    "                            **study.best_params)\n",
    "cat.fit(Xy2.drop(columns = [\"timestamp\", \"ID\",\"price\"]), Xy2[\"price\"])\n",
    "\n",
    "pred2 = cat.predict(answer_tg2.drop(columns = [\"ID\"]))\n",
    "for idx in range(len(pred2)):\n",
    "    if pred2[idx]<0:\n",
    "        pred2[idx]= 0\n",
    "answer_tg2[\"answer\"] = np.power(pred2,2)\n",
    "\n",
    "answer_tg2[[\"ID\",\"answer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TG 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "total1 = pd.concat([answer_tg1[[\"ID\",\"answer\"]],answer_notg[[\"ID\",\"answer\"]]])\n",
    "total2 = pd.concat([answer_tg2[[\"ID\",\"answer\"]],answer_notg[[\"ID\",\"answer\"]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1092, 2)\n",
      "(1092, 2)\n"
     ]
    }
   ],
   "source": [
    "print(total1.shape)\n",
    "print(total2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TG 앙상블 (평균)\n",
    "\n",
    "df = pd.merge(total1, total2, how = \"inner\", on=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer_x</th>\n",
       "      <th>answer_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TG_A_J_20230304</td>\n",
       "      <td>2735.490800</td>\n",
       "      <td>2817.542087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG_E_S_20230304</td>\n",
       "      <td>3380.409401</td>\n",
       "      <td>3409.830275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TG_E_J_20230304</td>\n",
       "      <td>593.513615</td>\n",
       "      <td>1019.689881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TG_D_S_20230304</td>\n",
       "      <td>3636.158665</td>\n",
       "      <td>3646.742081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TG_D_J_20230304</td>\n",
       "      <td>177.123287</td>\n",
       "      <td>576.703029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>RD_D_S_20230331</td>\n",
       "      <td>484.292780</td>\n",
       "      <td>484.292780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>CR_C_J_20230331</td>\n",
       "      <td>1773.018243</td>\n",
       "      <td>1773.018243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>RD_D_J_20230331</td>\n",
       "      <td>444.345799</td>\n",
       "      <td>444.345799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>CR_D_J_20230331</td>\n",
       "      <td>1939.259611</td>\n",
       "      <td>1939.259611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>RD_F_J_20230331</td>\n",
       "      <td>541.965754</td>\n",
       "      <td>541.965754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID     answer_x     answer_y\n",
       "0     TG_A_J_20230304  2735.490800  2817.542087\n",
       "1     TG_E_S_20230304  3380.409401  3409.830275\n",
       "2     TG_E_J_20230304   593.513615  1019.689881\n",
       "3     TG_D_S_20230304  3636.158665  3646.742081\n",
       "4     TG_D_J_20230304   177.123287   576.703029\n",
       "...               ...          ...          ...\n",
       "1087  RD_D_S_20230331   484.292780   484.292780\n",
       "1088  CR_C_J_20230331  1773.018243  1773.018243\n",
       "1089  RD_D_J_20230331   444.345799   444.345799\n",
       "1090  CR_D_J_20230331  1939.259611  1939.259611\n",
       "1091  RD_F_J_20230331   541.965754   541.965754\n",
       "\n",
       "[1092 rows x 3 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"answer\"] = (df[\"answer_x\"]+df[\"answer_y\"])/2\n",
    "df[\"item\"] = df[\"ID\"].map(lambda x :x.split(\"_\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 후처리 \n",
    "## 전체 min값 | 3월의 min값 확인\n",
    "df.loc[(df['item']=='TG')&(df['answer']<400),'answer'] =0 # 551   #3월 675\n",
    "df.loc[(df['item']=='CB')&(df['answer']<50),'answer'] =0 # 162  # 3월 200\n",
    "df.loc[(df['item']=='RD')&(df['answer']<10),'answer'] =0 # 50     # 3월 124\n",
    "df.loc[(df['item']=='CR')&(df['answer']<150),'answer'] =0 # 250   # 3월 450\n",
    "df.loc[(df['item']=='BC')&(df['answer']<100),'answer'] =0 #205 3월 205.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TG_A_J_20230304</td>\n",
       "      <td>2776.516443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TG_E_S_20230304</td>\n",
       "      <td>3395.119838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TG_E_J_20230304</td>\n",
       "      <td>806.601748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TG_D_S_20230304</td>\n",
       "      <td>3641.450373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TG_D_J_20230304</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>RD_D_S_20230331</td>\n",
       "      <td>484.292780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>CR_C_J_20230331</td>\n",
       "      <td>1773.018243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>RD_D_J_20230331</td>\n",
       "      <td>444.345799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>CR_D_J_20230331</td>\n",
       "      <td>1939.259611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>RD_F_J_20230331</td>\n",
       "      <td>541.965754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1092 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID       answer\n",
       "0     TG_A_J_20230304  2776.516443\n",
       "1     TG_E_S_20230304  3395.119838\n",
       "2     TG_E_J_20230304   806.601748\n",
       "3     TG_D_S_20230304  3641.450373\n",
       "4     TG_D_J_20230304     0.000000\n",
       "...               ...          ...\n",
       "1087  RD_D_S_20230331   484.292780\n",
       "1088  CR_C_J_20230331  1773.018243\n",
       "1089  RD_D_J_20230331   444.345799\n",
       "1090  CR_D_J_20230331  1939.259611\n",
       "1091  RD_F_J_20230331   541.965754\n",
       "\n",
       "[1092 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = [\"answer_x\",\"answer_y\", \"item\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용\n",
    "df.to_csv('/mnt/c/Users/wschu/OneDrive/Documents/data/jeju_specialty/open/answer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
